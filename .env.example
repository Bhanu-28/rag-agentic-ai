# ==================================================
# API Keys Configuration Template
# ==================================================
# 
# Instructions:
# 1. Copy this file to .env: cp .env.example .env
# 2. Replace the placeholder values with your actual API keys
# 3. Never commit your .env file to version control
#
# ==================================================

# OpenAI API Configuration
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-4  # Optional: default model to use
OPENAI_ORG_ID=      # Optional: OpenAI organization ID

# Anthropic (Claude) API Configuration
ANTHROPIC_API_KEY=your_anthropic_api_key_here
ANTHROPIC_MODEL=claude-3-opus-20240229  

OPEN_ROUTER_API_KEY =your_open_router_api_key_here


# Google AI (Gemini) API Configuration
GOOGLE_API_KEY=your_google_ai_api_key_here
GOOGLE_MODEL=gemini-pro  

# Cohere API Configuration
COHERE_API_KEY=your_cohere_api_key_here

# Hugging Face API Configuration
HUGGINGFACE_API_KEY=your_huggingface_api_key_here
HUGGINGFACE_MODEL=  # Optional: specific model to use

# Pinecone Vector Database Configuration
PINECONE_API_KEY=your_pinecone_api_key_here
PINECONE_ENVIRONMENT=your_pinecone_environment_here
PINECONE_INDEX_NAME=your_index_name_here

# Weaviate Vector Database Configuration
WEAVIATE_URL=your_weaviate_url_here
WEAVIATE_API_KEY=your_weaviate_api_key_here

# Qdrant Vector Database Configuration
QDRANT_URL=your_qdrant_url_here
QDRANT_API_KEY=your_qdrant_api_key_here

# LangSmith (for tracing and monitoring)
LANGSMITH_API_KEY=your_langsmith_api_key_here
LANGSMITH_PROJECT=your_project_name_here

# ==================================================
# Ollama (Local LLM) Configuration
# ==================================================
# Use this for free, local LLM inference
# See OLLAMA_SETUP.md for setup instructions

# Combined setup (single container)
OLLAMA_LLM_URL=http://localhost:11434
OLLAMA_EMBED_URL=http://localhost:11434

# Separate setup (uncomment for docker-compose.separate.yml)
# OLLAMA_LLM_URL=http://localhost:11434
# OLLAMA_EMBED_URL=http://localhost:11435

OLLAMA_LLM_MODEL=qwen2.5-coder:3b
OLLAMA_EMBED_MODEL=nomic-embed-text:v1.5

# Application Settings
APP_ENV=development  # development, staging, production
LOG_LEVEL=INFO       # DEBUG, INFO, WARNING, ERROR
